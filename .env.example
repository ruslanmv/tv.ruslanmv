# TV.RUSLANMV.COM - Environment Configuration
# Copy this file to .env and fill in your values

# ============================================================================
# GENERAL
# ============================================================================
ENVIRONMENT=development  # development, staging, production
NODE_ENV=development
LOG_LEVEL=info

# ============================================================================
# DATABASE
# ============================================================================
DATABASE_URL=postgresql://tvuser:changeme123@localhost:5432/tvruslanmv
DB_PASSWORD=changeme123

# ============================================================================
# REDIS
# ============================================================================
REDIS_URL=redis://localhost:6379/0

# ============================================================================
# OLLAMA - LOCAL LLM (DEFAULT - FREE)
# ============================================================================
# Ollama runs locally and provides free, fast AI inference
# Perfect for development and CI/CD workflows

OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=gemma:2b  # Options: gemma:2b, llama3.1:8b, mistral:7b

# LLM Configuration
NEWS_LLM_MODEL=ollama/gemma:2b  # DEFAULT: Use local Ollama
NEWS_LLM_TEMPERATURE=0.7
NEWS_LLM_MAX_TOKENS=2000

# Recommended models by use case:
# - ollama/gemma:2b         -> Fast, good for development (DEFAULT)
# - ollama/llama3.1:8b      -> Better quality, still local
# - ollama/mistral:7b       -> Alternative, good balance

# ============================================================================
# IBM WATSONX.AI (OPTIONAL - FOR BETTER QUALITY)
# ============================================================================
# Use watsonx.ai for production-grade quality
# To enable: Set NEWS_LLM_MODEL=watsonx/ibm/granite-13b-chat-v2
# Get your API key from: https://cloud.ibm.com/

WATSONX_APIKEY=
WATSONX_PROJECT_ID=
WATSONX_URL=https://us-south.ml.cloud.ibm.com

# Recommended watsonx models:
# - watsonx/ibm/granite-13b-chat-v2          -> IBM's model, good quality
# - watsonx/meta-llama/llama-3-1-70b-instruct -> Best quality, slower
# - watsonx/ibm/granite-20b-multilingual     -> Multilingual support

# Example to use watsonx.ai:
# NEWS_LLM_MODEL=watsonx/ibm/granite-13b-chat-v2

# ============================================================================
# OTHER LLM PROVIDERS (OPTIONAL)
# ============================================================================

# OpenAI (alternative)
OPENAI_API_KEY=
# To use: NEWS_LLM_MODEL=openai/gpt-4o-mini

# Anthropic Claude (alternative)
ANTHROPIC_API_KEY=
# To use: NEWS_LLM_MODEL=anthropic/claude-3-5-sonnet-latest

# ============================================================================
# YOUTUBE API (REQUIRED FOR VIDEO UPLOAD)
# ============================================================================
# Setup: https://console.cloud.google.com/apis/credentials
YOUTUBE_API_KEY=your_youtube_api_key_here
YOUTUBE_CLIENT_ID=your_youtube_client_id_here
YOUTUBE_CLIENT_SECRET=your_youtube_client_secret_here
YOUTUBE_REFRESH_TOKEN=your_youtube_refresh_token_here

# YouTube channel configuration
YOUTUBE_CHANNEL_ID=your_channel_id
YOUTUBE_UPLOAD_DEFAULTS_CATEGORY=28  # Science & Technology
YOUTUBE_UPLOAD_DEFAULTS_PRIVACY=public  # public, unlisted, private

# ============================================================================
# TEXT-TO-SPEECH (Choose one)
# ============================================================================

# Option 1: ElevenLabs (Premium quality - RECOMMENDED)
ELEVENLABS_API_KEY=
ELEVENLABS_VOICE_ID=

# Option 2: OpenAI TTS (Good quality)
# OPENAI_API_KEY=your_openai_api_key_here
OPENAI_TTS_MODEL=tts-1-hd
OPENAI_TTS_VOICE=onyx  # alloy, echo, fable, onyx, nova, shimmer

# Option 3: Google Cloud TTS (Free alternative)
GOOGLE_CLOUD_TTS_KEY=

# ============================================================================
# FRONTEND
# ============================================================================
NEXT_PUBLIC_API_URL=http://localhost:8000
NEXT_PUBLIC_MCP_WS_URL=ws://localhost:3000
NEXT_PUBLIC_SITE_URL=http://localhost:3001
NEXT_PUBLIC_YOUTUBE_API_KEY=${YOUTUBE_API_KEY}

# Analytics (optional)
NEXT_PUBLIC_GA_ID=G-XXXXXXXXXX
NEXT_PUBLIC_PLAUSIBLE_DOMAIN=tv.ruslanmv.com

# ============================================================================
# BACKEND API
# ============================================================================
API_BASE_URL=http://localhost:8000
API_VERSION=v1
API_RATE_LIMIT=100  # requests per minute
API_CORS_ORIGINS=http://localhost:3001,http://localhost:3000

# JWT Configuration (for future auth)
JWT_SECRET_KEY=your_super_secret_jwt_key_change_this_in_production
JWT_ALGORITHM=HS256
JWT_EXPIRATION_MINUTES=1440

# ============================================================================
# MCP SERVER
# ============================================================================
MCP_SERVER_PORT=3000
MCP_API_BASE_URL=http://localhost:8000
MCP_ENABLE_AUTH=false  # Set to true in production

# ============================================================================
# CONTENT GENERATION
# ============================================================================

# News sources
NEWS_SCRAPER_SOURCES=hackernews,aiweekly,techcrunch,arxiv
NEWS_SCRAPER_INTERVAL=3600  # seconds

# Package tracking
PACKAGE_TRACKER_SOURCES=pypi,github,npm
PACKAGE_TRACKER_UPDATE_INTERVAL=86400  # 24 hours

# Research papers
ARXIV_API_BASE=http://export.arxiv.org/api/query
ARXIV_CATEGORIES=cs.AI,cs.LG,cs.CL

# CrewAI configuration
CREWAI_VERBOSE=true
CREWAI_MEMORY=true
CREWAI_MAX_RPM=10

# ============================================================================
# VIDEO PROCESSING
# ============================================================================
VIDEO_OUTPUT_DIR=/app/output
VIDEO_RESOLUTION=1920x1080
VIDEO_FPS=30
VIDEO_BITRATE=5000k
VIDEO_CODEC=libx264
AUDIO_CODEC=aac
AUDIO_BITRATE=192k

# Subtitle configuration
SUBTITLE_FONT=Arial
SUBTITLE_SIZE=48
SUBTITLE_COLOR=white

# ============================================================================
# GITHUB ACTIONS (for CI/CD)
# ============================================================================
# These are set automatically in GitHub Actions
# GITHUB_TOKEN - Provided by GitHub
# GITHUB_REPOSITORY - Provided by GitHub
# GITHUB_RUN_NUMBER - Provided by GitHub

# ============================================================================
# MONITORING & LOGGING (Optional)
# ============================================================================

# Sentry
SENTRY_DSN=
SENTRY_ENVIRONMENT=${ENVIRONMENT}

# Prometheus
PROMETHEUS_PORT=9090

# ============================================================================
# EMAIL NOTIFICATIONS (Optional)
# ============================================================================
SMTP_HOST=smtp.gmail.com
SMTP_PORT=587
SMTP_USER=your_email@gmail.com
SMTP_PASSWORD=your_app_password
SMTP_FROM=noreply@tv.ruslanmv.com

# ============================================================================
# SECURITY
# ============================================================================

# CORS
CORS_ALLOW_ORIGINS=http://localhost:3001,http://localhost:3000
CORS_ALLOW_CREDENTIALS=true

# Rate limiting
RATE_LIMIT_ENABLED=true
RATE_LIMIT_REQUESTS_PER_MINUTE=60

# SSL/TLS (Production)
SSL_ENABLED=false
SSL_CERT_PATH=/etc/ssl/certs/tv.ruslanmv.com.crt
SSL_KEY_PATH=/etc/ssl/private/tv.ruslanmv.com.key

# ============================================================================
# FEATURE FLAGS
# ============================================================================
FEATURE_MCP_SERVER=true
FEATURE_VIDEO_GENERATION=true
FEATURE_AUTO_UPLOAD=true
FEATURE_ANALYTICS=true
FEATURE_SEARCH=true
FEATURE_OLLAMA=true  # Use local Ollama
FEATURE_WATSONX=false  # Use watsonx.ai (requires API key)

# ============================================================================
# DEPLOYMENT
# ============================================================================

# Docker
DOCKER_REGISTRY=ghcr.io
DOCKER_IMAGE_PREFIX=ruslanmv/tv-ruslanmv

# Kubernetes (if using)
K8S_NAMESPACE=tvruslanmv
K8S_CLUSTER=production

# ============================================================================
# CRON SCHEDULES (for GitHub Actions)
# ============================================================================
# Format: minute hour day month weekday
SCHEDULE_CONTENT_GENERATION=0 4 * * *  # Daily at 04:00 UTC (06:00 CET)
SCHEDULE_VIDEO_PROCESSING=0 5 * * *    # Daily at 05:00 UTC
SCHEDULE_YOUTUBE_UPLOAD=0 6 * * *      # Daily at 06:00 UTC

# ============================================================================
# TESTING
# ============================================================================
TEST_DATABASE_URL=postgresql://tvuser:testpass@localhost:5433/tvruslanmv_test
TEST_REDIS_URL=redis://localhost:6380/0

# ============================================================================
# QUICK START GUIDE
# ============================================================================
#
# 1. MINIMUM REQUIRED (for local development):
#    - DATABASE_URL (or use docker-compose defaults)
#    - OLLAMA_HOST (auto-configured if using docker-compose)
#    - Nothing else! Ollama is free and local
#
# 2. FOR VIDEO UPLOAD:
#    - YOUTUBE_API_KEY, YOUTUBE_CLIENT_ID, YOUTUBE_CLIENT_SECRET, YOUTUBE_REFRESH_TOKEN
#    - ELEVENLABS_API_KEY or OPENAI_API_KEY (for TTS)
#
# 3. FOR BETTER QUALITY (OPTIONAL):
#    - Set NEWS_LLM_MODEL=watsonx/ibm/granite-13b-chat-v2
#    - Add WATSONX_APIKEY and WATSONX_PROJECT_ID
#
# 4. FOR GITHUB ACTIONS:
#    - Set all above as GitHub Secrets
#    - Workflow will automatically use Ollama in CI (free)
#
# ============================================================================
# NOTES
# ============================================================================
# 1. Never commit this file with actual credentials
# 2. Ollama is used by default (free, local, fast)
# 3. watsonx.ai is optional for better quality
# 4. Use strong passwords in production
# 5. Rotate API keys regularly
# 6. Enable SSL/TLS in production
# ============================================================================
